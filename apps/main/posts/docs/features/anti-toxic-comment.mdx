---
title: Anti toxic comment
---

# Anti toxic comment

Toxic comment is very harmful to a health community but we dont want moderator spend a lot of efforts to maintain it. Thus we built a machine learning system to detect toxic comment if it is toxic it'll be blocked by our system by default.

## Example

There is a blocking popup that appears when a user posts a toxic comment.

![Example of toxic comment popup](/images/docs/features/anti-toxic-comment/example.png)

## Supported toxic labels

We use machine learning technologies to detect toxic comment. Currently, we support the following toxic labels:

- toxicity
- severe toxicity
- identity attack
- insult
- threat
- sexual_explicit
- obscene
